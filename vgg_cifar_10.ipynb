{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg-cifar-10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/icapucap/SE_project/blob/main/vgg_cifar_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwMSfMzJLjvh",
        "outputId": "488dfcfe-91ed-461f-c6c2-89e3a336542e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        }
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/14/9a2c792e48e01e55913b9495ce0e8a16297e2bc1cc99e86a848d205c91e7/wandb-0.10.5-py2.py3-none-any.whl (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 2.9MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n",
            "Collecting watchdog>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/06/121302598a4fc01aca942d937f4a2c33430b7181137b35758913a8db10ad/watchdog-0.10.3.tar.gz (94kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/df/1145dc9389138eb47649806b42aaad5b0ecdfd3e93c7c51c1fffd80a8f90/sentry_sdk-0.18.0-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 16.4MB/s \n",
            "\u001b[?25hCollecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/6b/01baa293090240cf0562cc5eccb69c6f5006282127f2b846fad011305c79/configparser-5.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.3)\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.15.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/d7/b2b0672e0331567157adf9281f41ee731c412ee518ca5e6552c27fa73c91/GitPython-3.1.9-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 16.2MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Collecting pathtools>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.12.0->wandb) (50.3.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.6MB/s \n",
            "\u001b[?25hCollecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: watchdog, subprocess32, pathtools\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-0.10.3-cp36-none-any.whl size=73873 sha256=853f8f10377e72d680bb1090042b1507d6342ba53bd0747760b0f15286ab2f0b\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/1d/38/2c19bb311f67cc7b4d07a2ec5ea36ab1a0a0ea50db994a5bc7\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=143071371063096567fa603fed297adf755983e1ea42c2779b0f32ac1ceb49b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8785 sha256=601d1b81112255c8b7cdf06ecc65a1ff8f6e34a70e8449543627bcf62a448c02\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built watchdog subprocess32 pathtools\n",
            "Installing collected packages: shortuuid, pathtools, watchdog, sentry-sdk, configparser, subprocess32, smmap, gitdb, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.9 configparser-5.0.0 docker-pycreds-0.4.0 gitdb-4.0.5 pathtools-0.1.2 sentry-sdk-0.18.0 shortuuid-1.0.1 smmap-3.0.4 subprocess32-3.5.4 wandb-0.10.5 watchdog-0.10.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9xxkbkFB60U"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.constraints import maxnorm\n",
        "from keras.optimizers import SGD,Adam\n",
        "from keras.layers import Activation\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.initializers import glorot_normal\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "from keras.datasets import cifar10\n",
        "from keras.callbacks import  EarlyStopping, LearningRateScheduler\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import to_categorical\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers.schedules import ExponentialDecay\n",
        "\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "wandb.init(project=\"vgg-cifar10\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMcbIP_jCP1x"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 100\n",
        "learning_rate = 0.05\n",
        "lr_decay = 1e-6\n",
        "lr_drop = 20\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "x_train  /= 255\n",
        "x_test /= 255\n",
        "\n",
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']\n",
        "               \n",
        "datagen = ImageDataGenerator(\n",
        "            featurewise_center=False, \n",
        "            samplewise_center=False,  \n",
        "            featurewise_std_normalization=False,  \n",
        "            samplewise_std_normalization=False,  \n",
        "            zca_whitening=False,  \n",
        "            rotation_range=15,  \n",
        "            width_shift_range=0.1,  \n",
        "            height_shift_range=0.1,  \n",
        "            horizontal_flip=True, \n",
        "            vertical_flip=False)  \n",
        "      \n",
        "datagen.fit(x_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLWt1VYyKrTf"
      },
      "source": [
        "BATCH_NORM = True\n",
        "num_classes=10\n",
        "\n",
        "def base_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', input_shape=x_train.shape[1:], name='block1_conv1'))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', name='block1_conv2', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), padding='same', name='block2_conv1', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), padding='same', name='block2_conv2', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), padding='same', name='block3_conv1', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), padding='same', name='block3_conv2', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), padding='same', name='block3_conv3', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), padding='same', name='block3_conv4', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same', name='block4_conv1', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same', name='block4_conv2', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same', name='block4_conv3', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same', name='block4_conv4', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool'))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same', name='block5_conv1', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same', name='block5_conv2', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same', name='block5_conv3', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same', name='block5_conv4', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(4096, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(4096, name='fc2', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(num_classes))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    sgd = SGD(lr=learning_rate, decay=lr_decay, momentum=0.75, nesterov=True)\n",
        "    # lr_schedule = ExponentialDecay(\n",
        "    # initial_learning_rate=1e-2,\n",
        "    # decay_steps=10000,\n",
        "    # decay_rate=0.8)\n",
        "    # optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "cnn_n = base_model()\n",
        "cnn_n.summary()\n",
        "\n",
        "cnn_n.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                         batch_size=batch_size),\n",
        "                            steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                            epochs=epochs,\n",
        "                            validation_data=(x_test, y_test),callbacks=[WandbCallback(data_type=\"image\", validation_data=(x_test, y_test), labels=class_names),\n",
        "                               EarlyStopping(patience=15, restore_best_weights=True)],verbose=2)\n",
        "#cnn_n.save_weights('cifar10vgg.h5')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le_5MDJVKyHi"
      },
      "source": [
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "Y_pred = cnn_n.predict(x_test, verbose=2)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "for ix in range(10):\n",
        "    print(ix, confusion_matrix(np.argmax(y_test,axis=1),y_pred)[ix].sum())\n",
        "cm = confusion_matrix(np.argmax(y_test,axis=1),y_pred)\n",
        "print(cm)\n",
        "\n",
        "# Visualizing of confusion matrix\n",
        "import seaborn as sn\n",
        "import pandas  as pd\n",
        "\n",
        "\n",
        "df_cm = pd.DataFrame(cm, range(10),\n",
        "                  range(10))\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.set(font_scale=1.4)#for label size\n",
        "sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 12})# font size\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_YJFNqFT_I5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}