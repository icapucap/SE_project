{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg-ninv2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMLiuXv3R54z3gDdNBYczhE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/icapucap/SE_project/blob/main/vgg_ninv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_0PrV0cDGo-"
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKeSXVQIDLHy"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.constraints import maxnorm\n",
        "from keras.optimizers import SGD,Adam\n",
        "from keras.layers import Activation, AveragePooling2D\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers.pooling import GlobalAveragePooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.initializers import glorot_normal\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "from keras.datasets import cifar10\n",
        "from keras.callbacks import  EarlyStopping, LearningRateScheduler\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import to_categorical\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers.schedules import ExponentialDecay\n",
        "from keras.metrics import AUC\n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNHCZXcVDNr0"
      },
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "wandb.init(project=\"vgg-cifar10_ninv2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLP7TIdcDPvX"
      },
      "source": [
        "# data loading and preprocessing\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 50\n",
        "learning_rate = 0.05\n",
        "lr_decay = 1e-6\n",
        "lr_drop = 20\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "x_train  /= 255\n",
        "x_test /= 255\n",
        "\n",
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']\n",
        "               \n",
        "datagen = ImageDataGenerator(\n",
        "            featurewise_center=False, \n",
        "            samplewise_center=False,  \n",
        "            featurewise_std_normalization=False,  \n",
        "            samplewise_std_normalization=False,  \n",
        "            zca_whitening=False,  \n",
        "            rotation_range=15,  \n",
        "            width_shift_range=0.1,  \n",
        "            height_shift_range=0.1,  \n",
        "            horizontal_flip=True, \n",
        "            vertical_flip=False)  \n",
        "      \n",
        "datagen.fit(x_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iuj-s90GDSPr"
      },
      "source": [
        "BATCH_NORM = True\n",
        "num_classes=10\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feuuBZ7ADZv2"
      },
      "source": [
        "def base_model_with_ninv2():\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', input_shape=x_train.shape[1:], name='block1_conv1'))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(64, (1, 1), padding='same', name='block1_conv2nin1'))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(64, (1, 1), padding='same', name='block1_conv2nin2'))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(64, (1, 1), padding='same', name='block1_conv2nin3'))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(AveragePooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), padding='same', name='block2_conv1' ))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(128, (1, 1), padding='same', name='block2_conv2nin1' ))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(128, (1, 1), padding='same', name='block2_conv2nin2' ))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(64, (1, 1), padding='same', name='block2_conv2nin3'))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(AveragePooling2D((2, 2), strides=(2, 2), name='block2_pool'))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), padding='same', name='block3_conv1' ))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(256, (1, 1), padding='same', name='block3_conv2nin1' ))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(256, (1, 1), padding='same', name='block3_conv3nin2' ))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(256, (1, 1), padding='same', name='block3_conv4nin3' ))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(AveragePooling2D((2, 2), strides=(2, 2), name='block3_pool'))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same', name='block4_conv1' ))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(512, (1, 1), padding='same', name='block4_conv2nin1' ))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(512, (1, 1), padding='same', name='block4_conv3nin2' ))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(512, (1, 1), padding='same', name='block4_conv4nin3' ))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(AveragePooling2D((2, 2), strides=(2, 2), name='block4_pool'))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same', name='block5_conv1' ))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(512, (1, 1), padding='same', name='block5_conv2nin1' ))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(512, (1, 1), padding='same', name='block5_conv3nin2' ))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(512, (1, 1), padding='same', name='block5_conv4nin3' ))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(10, (1, 1), padding='same', name='block5_convlast' ))\n",
        "    model.add(BatchNormalization()) if BATCH_NORM else None\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    # sgd = SGD(lr=learning_rate, decay=lr_decay, momentum=0.75, nesterov=True)\n",
        "    lr_schedule = ExponentialDecay(\n",
        "    initial_learning_rate=5e-4,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.85)\n",
        "    optimizer = Adam(learning_rate=lr_schedule)\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer,metrics=['accuracy', AUC()])\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo3vQJvyDanY"
      },
      "source": [
        "# prints model summary and also stores the same as an image in png format\n",
        "\n",
        "cnn_n = base_model_with_ninv2()\n",
        "cnn_n.summary()\n",
        "plot_model(cnn_n, to_file='ninv2.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gszpY8xfDhGt"
      },
      "source": [
        "cnn_n.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                         batch_size=batch_size),\n",
        "                            steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                            epochs=epochs,\n",
        "                            validation_data=(x_test, y_test),callbacks=[WandbCallback(data_type=\"image\", validation_data=(x_test, y_test), labels=class_names),\n",
        "                               EarlyStopping(monitor='val_accuracy',patience=5, restore_best_weights=True)],verbose=2)\n",
        "#cnn_n.save_weights('cifar10vgg.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBxpOcI_DnVb"
      },
      "source": [
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "Y_pred = cnn_n.predict(x_test, verbose=2)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "for ix in range(10):\n",
        "    print(ix, confusion_matrix(np.argmax(y_test,axis=1),y_pred)[ix].sum())\n",
        "cm = confusion_matrix(np.argmax(y_test,axis=1),y_pred)\n",
        "print(cm)\n",
        "\n",
        "# Visualizing of confusion matrix\n",
        "import seaborn as sn\n",
        "import pandas  as pd\n",
        "\n",
        "\n",
        "df_cm = pd.DataFrame(cm, range(10),\n",
        "                  range(10))\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.set(font_scale=1.4)#for label size\n",
        "sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 12})# font size\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}